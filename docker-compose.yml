version: "3"

services:
  spark:
    build:
      context: .
      dockerfile: ./container/Dockerfile
    volumes:
      - ./src:/opt/project
    expose:
      - 4040
      - 8081
      - 7077
    ports:
      - 4040:4040
      - 7077:7077
      - 8081:8081
    restart: unless-stopped
    command: sh /run.sh
  # namenode:
  #   image: bde2020/hadoop-namenode:2.0.0-hadoop3.1.1-java8
  #   container_name: namenode
  #   environment:
  #     - CLUSTER_NAME=test
  #     - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
  #   env_file:
  #     - ./hadoop-hive.env
  #   ports:
  #     - 50070:50070
  # datanode:
  #   image: bde2020/hadoop-datanode:2.0.0-hadoop3.1.1-java8
  #   container_name: datanode
  #   depends_on:
  #     - namenode
  #   environment:
  #     - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
  #   env_file:
  #     - ./hadoop-hive.env
  #   ports:
  #     - 50075:50075
  # hue:
  #   image: bde2020/hdfs-filebrowser:3.11
  #   container_name: hue
  #   ports:
  #     - 8088:8088
  #   environment:
  #     - NAMENODE_HOST=namenode
